{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the spatial data representing OSM street network\n",
    "\n",
    "This notebook downloads the boundaries of FUAs from GHSL, randomly samples 25 larger than 1 million inhabitants from each continent to account for various sizes and geographical variation, and downloads street networks from OpenStreetMap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import geopandas\n",
    "import pandas\n",
    "import pooch\n",
    "import osmnx as ox\n",
    "import dask_geopandas\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data\n",
    "\n",
    "Download FUA polygons. We are using _GHS functional urban areas, derived from GHS-UCDB R2019A (2015)_ from [GHSL - Global Human Settlement Layer](https://ghsl.jrc.ec.europa.eu/ghs_fua.php)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data from 'https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/GHSL/GHS_FUA_UCDB2015_GLOBE_R2019A/V1-0/GHS_FUA_UCDB2015_GLOBE_R2019A_54009_1K_V1_0.zip' to file '/home/jovyan/.cache/pooch/42ab047cecb0653ef75601013a14e233-GHS_FUA_UCDB2015_GLOBE_R2019A_54009_1K_V1_0.zip'.\n"
     ]
    }
   ],
   "source": [
    "fua_path = \"https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/GHSL/GHS_FUA_UCDB2015_GLOBE_R2019A/V1-0/GHS_FUA_UCDB2015_GLOBE_R2019A_54009_1K_V1_0.zip\"\n",
    "\n",
    "fua_cache = pooch.retrieve(\n",
    "    fua_path,\n",
    "    known_hash=\"d54de59b82b8c4d64a710f90ccd554975a3be92233f14115ac154094c3549979\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read polygons and continent geometry (built-in dataset in geopandas coming from Natural Earth)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fua = geopandas.read_file(\n",
    "    f\"{fua_cache}!GHS_FUA_UCDB2015_GLOBE_R2019A_54009_1K_V1_0.gpkg\"\n",
    ")\n",
    "continents = geopandas.read_file(geopandas.datasets.get_path(\"naturalearth_lowres\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retain only FUAs with population (as of 2015) larger than 1 000 000 inhabitants. That ensures a reasonable size of a street network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fua = fua.query(\"FUA_p_2015 > 1000000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attach information on a continent to FUAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fua = fua.merge(\n",
    "    continents[[\"continent\", \"iso_a3\"]], left_on=\"Cntry_ISO\", right_on=\"iso_a3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample 25 FUAs from each continent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = []\n",
    "for continent in fua.continent.unique():\n",
    "    subset = fua[fua.continent == continent]\n",
    "    if len(subset) > 25:\n",
    "        sample.append(fua[fua.continent == continent].sample(25, random_state=42))\n",
    "    else:\n",
    "        sample.append(subset)\n",
    "sample = pandas.concat(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reproject geometry to WGS84 required by OSM and check geometry validity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample.to_crs(4326)\n",
    "if not sample.is_valid.all():\n",
    "    sample.geometry = sample.buffer(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over the sampled FUAs and download their street network from OSM. This step may take some time (~13 hours)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                         | 1/131 [00:20<43:32, 20.10s/it]IOStream.flush timed out\n",
      " 99%|███████████████████████████████████▋| 130/131 [12:40:07<14:55, 895.29s/it]IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "100%|████████████████████████████████████| 131/131 [12:53:30<00:00, 354.28s/it]\n"
     ]
    }
   ],
   "source": [
    "# Define which combination of OSM tags should be used. This covers what would be usually used in a morphological analysis.\n",
    "type_filter = '[\"highway\"~\"living_street|motorway|motorway_link|pedestrian|primary|primary_link|residential|secondary|secondary_link|service|tertiary|tertiary_link|trunk|trunk_link|unclassified\"]'\n",
    "\n",
    "# Loop over all samples\n",
    "for ix, row in tqdm(sample.iterrows(), total=len(sample)):\n",
    "    # Download OSM graph\n",
    "    streets_graph = ox.graph_from_polygon(\n",
    "        row.geometry,\n",
    "        network_type=\"all_private\",\n",
    "        custom_filter=type_filter,\n",
    "        retain_all=True,\n",
    "        simplify=False,\n",
    "    )\n",
    "    # Project graph to the local UTM zone (in meters with a reletively small error)\n",
    "    streets_graph = ox.projection.project_graph(streets_graph)\n",
    "    # Create an undirected graph to avoid duplicated geometry and convert it to a GeoDataFrame\n",
    "    gdf = ox.graph_to_gdfs(\n",
    "        ox.get_undirected(streets_graph),\n",
    "        nodes=False,\n",
    "        edges=True,\n",
    "        node_geometry=False,\n",
    "        fill_edge_geometry=True,\n",
    "    )\n",
    "    # Ensure tags are a string and not different dtype (as list) so we can save it\n",
    "    gdf.highway = gdf.highway.astype(str)\n",
    "\n",
    "    # Create a folder for the sample case\n",
    "    os.makedirs(f\"../data/{int(row.eFUA_ID)}\", exist_ok=True)\n",
    "\n",
    "    # Save the street network as a GeoParquet, using only necessary columns. We are not interested in other.\n",
    "    path = f\"../data/{int(row.eFUA_ID)}/roads_osm.parquet\"\n",
    "    gdf[[\"highway\", \"geometry\"]].to_parquet(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save sample boundaries containing names and continents for a future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_parquet(\"../data/sample.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split to partitions to fit into the GitHub filesize limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 131/131 [04:30<00:00,  2.06s/it]\n"
     ]
    }
   ],
   "source": [
    "for ix, row in tqdm(sample.iterrows(), total=len(sample)):\n",
    "    path = f\"../data/{int(row.eFUA_ID)}/roads_osm.parquet\"\n",
    "    polygons = dask_geopandas.from_geopandas(\n",
    "        geopandas.read_parquet(path).reset_index(), npartitions=2\n",
    "    )\n",
    "    os.remove(path)\n",
    "    polygons.to_parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "d8e5257d6aa3ccb45d262d25a4bd441591d0aff640b224e205b1e70b23b1db26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
