{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of distribution of shape statistics\n",
    "\n",
    "This notebook uses indices capturing relationship between shape metrics and area of polygons across all FUAs, identifies peaks and valleys in the distribution using KDE and assesses performance of each shape metric in distinguishing between face polygons and face artifacts.\n",
    "\n",
    "## Whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b0/lkvf88hn0673f5dlj9z0_2dr0000gn/T/ipykernel_46995/366580399.py:1: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas\n"
     ]
    }
   ],
   "source": [
    "import geopandas\n",
    "import pandas\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from palettable.cartocolors.qualitative import Bold_6\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "import os\n",
    "\n",
    "import pickle\n",
    "from collections import Counter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set default plotting theme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(\n",
    "    context=\"paper\",\n",
    "    style=\"ticks\",\n",
    "    rc={\n",
    "        \"patch.force_edgecolor\": False,\n",
    "        \"axes.spines.top\": False,\n",
    "        \"axes.spines.right\": False,\n",
    "        \"axes.grid\": True,\n",
    "    },\n",
    "    palette=Bold_6.hex_colors,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data and combine them to a single GeoDataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = geopandas.read_parquet(\"../data/sample.parquet\")\n",
    "\n",
    "all_poly = []\n",
    "for i, row in sample.iterrows():\n",
    "    fua = geopandas.read_parquet(f\"../data/{int(row.eFUA_ID)}/polygons/\")\n",
    "    fua[\"continent\"] = row.continent\n",
    "    fua[\"country\"] = row.Cntry_name\n",
    "    fua[\"name\"] = row.eFUA_name\n",
    "    fua.crs = None\n",
    "    all_poly.append(fua)\n",
    "all_poly_data = pandas.concat(all_poly).reset_index(drop=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set colors for continents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### @MARTIN IS THERE A MORE STRAIGHTFORWARD WAY TO DO THIS?\n",
    "# (to make sure that we always assign the same color to the same continent)\n",
    "# make color dictionary for continents to access seaborn palette by index\n",
    "continents = numpy.unique(all_poly_data[\"continent\"])\n",
    "coldict = {}\n",
    "for i, cont in enumerate(continents):\n",
    "    coldict[cont] = i\n",
    "# to access like :\n",
    "# sns.color_palette(n_colors = 6)[coldict[\"Africa\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of cities and a list of options.\n",
    "\n",
    "cities = numpy.unique(all_poly_data.name)\n",
    "\n",
    "options = [\n",
    "    \"circular_compactness_index\",\n",
    "    \"isoperimetric_quotient_index\",\n",
    "    \"isoareal_quotient_index\",\n",
    "    \"radii_ratio_index\",\n",
    "    \"diameter_ratio_index\"\n",
    "    ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now,\n",
    "- Find peaks in frequency distribution of each `option` for each `city`\n",
    "- Plot all options for each city for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding peaks for Abbottabad\n",
      "finding peaks for Abidjan\n",
      "finding peaks for Abuja\n",
      "finding peaks for Accra\n",
      "finding peaks for Addis Ababa\n",
      "finding peaks for Adelaide\n",
      "finding peaks for Agadir\n",
      "finding peaks for Agra\n",
      "finding peaks for Al-Zaqaziq‎\n",
      "finding peaks for Aleppo\n",
      "finding peaks for Amaigbo\n",
      "finding peaks for Amsterdam\n",
      "finding peaks for Athens\n",
      "finding peaks for Auckland\n",
      "finding peaks for Barcelona\n",
      "finding peaks for Basra\n",
      "finding peaks for Belgrade\n",
      "finding peaks for Belo Horizonte\n",
      "finding peaks for Belém\n",
      "finding peaks for Brisbane\n",
      "finding peaks for Bucaramanga\n",
      "finding peaks for Buenos Aires\n",
      "finding peaks for Cali\n",
      "finding peaks for Cape Town\n",
      "finding peaks for Cardiff\n",
      "finding peaks for Chelyabinsk\n",
      "finding peaks for Chongqing\n",
      "finding peaks for Cincinnati\n",
      "finding peaks for Cochabamba\n",
      "finding peaks for Cologne\n",
      "finding peaks for Comilla\n",
      "finding peaks for Conakry\n",
      "finding peaks for Curitiba\n",
      "finding peaks for Dallas\n",
      "finding peaks for Dhaka\n",
      "finding peaks for Dortmund\n",
      "finding peaks for Douala\n",
      "finding peaks for Fez\n",
      "finding peaks for Glasgow\n",
      "finding peaks for Gonda\n",
      "finding peaks for Guangzhou\n",
      "finding peaks for Guatemala City\n",
      "finding peaks for Helsinki\n",
      "finding peaks for Ibadan\n",
      "finding peaks for Jaipur\n",
      "finding peaks for Jombang\n",
      "finding peaks for Kabul\n",
      "finding peaks for Kananga\n",
      "finding peaks for Kansas City\n",
      "finding peaks for Karachi\n",
      "finding peaks for Katowice\n",
      "finding peaks for Khartoum\n",
      "finding peaks for Krakow\n",
      "finding peaks for Kyiv\n",
      "finding peaks for Las Vegas\n",
      "finding peaks for Leeds\n",
      "finding peaks for Lima\n",
      "finding peaks for Lisbon\n",
      "finding peaks for Liège\n",
      "finding peaks for London\n",
      "finding peaks for Lucknow\n",
      "finding peaks for Luohe\n",
      "finding peaks for Maceió\n",
      "finding peaks for Maiduguri\n",
      "finding peaks for Managua\n",
      "finding peaks for Manaus\n",
      "finding peaks for Mandalay\n",
      "finding peaks for Maracaibo\n",
      "finding peaks for Maracay\n",
      "finding peaks for Medellín\n",
      "finding peaks for Melbourne\n",
      "finding peaks for Mendoza\n",
      "finding peaks for Mogadishu\n",
      "finding peaks for Mombasa\n",
      "finding peaks for Monrovia\n",
      "finding peaks for Montreal\n",
      "finding peaks for Moscow\n",
      "finding peaks for N'Djamena\n",
      "finding peaks for Nantong\n",
      "finding peaks for Natal\n",
      "finding peaks for Niamey\n",
      "finding peaks for Nuremberg\n",
      "finding peaks for Oran\n",
      "finding peaks for Orlando\n",
      "finding peaks for Ottawa\n",
      "finding peaks for Ouagadougou\n",
      "finding peaks for Perth\n",
      "finding peaks for Philadelphia\n",
      "finding peaks for Pittsburgh\n",
      "finding peaks for Porto Alegre\n",
      "finding peaks for Qinhuangdao\n",
      "finding peaks for Quito\n",
      "finding peaks for Raleigh\n",
      "finding peaks for Recife\n",
      "finding peaks for Richmond\n",
      "finding peaks for Rosario\n",
      "finding peaks for Río Piedras [San Juan]\n",
      "finding peaks for Sacramento\n",
      "finding peaks for Salt Lake City\n",
      "finding peaks for Salvador\n",
      "finding peaks for San Jose\n",
      "finding peaks for San Salvador\n",
      "finding peaks for Santiago\n",
      "finding peaks for Santos\n",
      "finding peaks for Saratov\n",
      "finding peaks for Semarang\n",
      "finding peaks for Seoul\n",
      "finding peaks for Seville\n",
      "finding peaks for Sofia\n",
      "finding peaks for St. Louis\n",
      "finding peaks for Sydney\n",
      "finding peaks for São Luís\n",
      "finding peaks for São Paulo\n",
      "finding peaks for Tanta\n",
      "finding peaks for Tbilisi\n",
      "finding peaks for Tegucigalpa\n",
      "finding peaks for Tijuana\n",
      "finding peaks for Toluca\n",
      "finding peaks for Torreon\n",
      "finding peaks for Tripoli\n",
      "finding peaks for Tunis\n",
      "finding peaks for Valencia\n",
      "finding peaks for Vancouver\n",
      "finding peaks for Vienna\n",
      "finding peaks for Voronezh\n",
      "finding peaks for Warsaw\n",
      "finding peaks for Washington D.C.\n",
      "finding peaks for Weifang\n",
      "finding peaks for Wuhan\n",
      "finding peaks for Xingtai\n",
      "finding peaks for Yongkang\n"
     ]
    }
   ],
   "source": [
    "# LINSPACE ADJUSTED\n",
    "\n",
    "# Fits a Gaussian kernel density estimation with Silverman bandwith method\n",
    "# Finds peaks in the estimated probability density function; \n",
    "# Parameters as little restrictive as possible;\n",
    "# Linspace adjusted to number of data points in input data\n",
    "\n",
    "# initiate dict to store results\n",
    "results_linspace_adjusted = {}\n",
    "\n",
    "for city in cities:\n",
    "\n",
    "    print(\"finding peaks for\", city)\n",
    "\n",
    "    # to store results\n",
    "    results_linspace_adjusted[city] = {}\n",
    "\n",
    "    # initiate plot\n",
    "    fig, ax = plt.subplots(1,5,figsize = (20,5))\n",
    "    \n",
    "    # find kde pdf and peaks for each of the options\n",
    "    for i, option in enumerate(options):\n",
    "        \n",
    "        results_linspace_adjusted[city][option] = {}\n",
    "        \n",
    "        # get data\n",
    "        fua = all_poly_data[all_poly_data.name == city]\n",
    "        data = numpy.log(fua[option])\n",
    "\n",
    "        # adjust linspace to be sparser than observations (linspace contains 10x less datapoints than original data)\n",
    "        n = int(len(fua)/10)\n",
    "        mylinspace = numpy.linspace(data.min(), data.max(), n)\n",
    "\n",
    "        # fit Gaussian KDE\n",
    "        kde = gaussian_kde(data, bw_method=\"silverman\")\n",
    "        pdf = kde.pdf(mylinspace)\n",
    "\n",
    "        # find peaks\n",
    "        peaks, d = find_peaks(\n",
    "            x = -pdf +1,\n",
    "            height = (0,.995),\n",
    "            threshold = None,\n",
    "            distance = None,\n",
    "            prominence = 0.0005,\n",
    "            width = 1,\n",
    "            plateau_size = None)\n",
    "        \n",
    "        # store results\n",
    "        results_linspace_adjusted[city][option][\"mylinspace\"] = mylinspace\n",
    "        results_linspace_adjusted[city][option][\"pdf\"] = pdf\n",
    "        results_linspace_adjusted[city][option][\"peaks\"] = peaks\n",
    "        results_linspace_adjusted[city][option][\"d\"] = d\n",
    "\n",
    "        # add subplot\n",
    "\n",
    "        ax[i].plot(pdf, color = \"grey\")\n",
    "        ax[i].scatter(\n",
    "            x = peaks, \n",
    "            y = pdf[peaks], \n",
    "            color = sns.color_palette(n_colors = 6)[coldict[numpy.max(fua[\"continent\"])]], \n",
    "            s = 8, \n",
    "            alpha = 0.7);\n",
    "        ax[i].set_xlabel(option)\n",
    "        ax[i].set_ylim([0,1])\n",
    "    \n",
    "    plt.suptitle(city)\n",
    "\n",
    "    # store plot for this city\n",
    "    fig.savefig(f\"../results/linspace_adjusted/allmins_{city}.png\", dpi = 400)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results as pickle\n",
    "with open('../results/results_linspace_adjusted.pickle', 'wb') as handle:\n",
    "    pickle.dump(results_linspace_adjusted, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating which option finds the most banana minima:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "circular_compactness_index\n",
      "Counter({1: 113, 0: 12, 2: 6})\n",
      "isoperimetric_quotient_index\n",
      "Counter({1: 102, 0: 21, 2: 7, 3: 1})\n",
      "isoareal_quotient_index\n",
      "Counter({1: 75, 0: 45, 2: 11})\n",
      "radii_ratio_index\n",
      "Counter({1: 81, 0: 41, 2: 9})\n",
      "diameter_ratio_index\n",
      "Counter({1: 100, 0: 19, 2: 12})\n"
     ]
    }
   ],
   "source": [
    "for option in options:\n",
    "    print(option)\n",
    "    print(Counter([len(results_linspace_adjusted[city][option][\"peaks\"]) for city in cities]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**conclusion: the circular compactness index seems to be a clear winner**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OSMNX",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35f35e1f0bb92e7ac05765c87ada263d1a2173e12d4a4460e46e5d1567b982a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
