{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draft of semi-automated banana validation\n",
    "### with building data from OSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## shapely 2.0.0.!\n",
    "import shapely\n",
    "from shapely import strtree\n",
    "from shapely.geometry import LineString\n",
    "from shapely.validation import make_valid\n",
    "\n",
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "# import pygeos\n",
    "\n",
    "import geopandas\n",
    "import pandas\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from palettable.cartocolors.qualitative import Bold_6\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import osmnx as ox"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in face polygons\n",
    "\"Mini\" version looks at only 1 city (Vienna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = \"Vienna\"\n",
    "# sample meta data\n",
    "sample = geopandas.read_parquet(\"../data/sample.parquet\")\n",
    "sample_mini = sample[sample.eFUA_name.isin([city])]\n",
    "\n",
    "# face polygon data\n",
    "city_id = int(sample[sample.eFUA_name == \"Vienna\"][\"eFUA_ID\"])\n",
    "# read in face polygons \n",
    "facepoly = geopandas.read_parquet(f\"../data/{int(city_id)}/polygons/\")\n",
    "# drop not needed colums and reset index\n",
    "facepoly = facepoly[[\"geometry\", \"circular_compactness_index\"]]\n",
    "facepoly = facepoly.reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify face polygons into bananas and non-bananas with help of banana index:\n",
    "- read in data\n",
    "- apply peak finding procedure from `04_DRAFT_peaks` (with circular compactness index as indicator)\n",
    "- classify face polygons into (potential) bananas and non-bananas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "banana value found for Vienna: 523.0864515304407\n"
     ]
    }
   ],
   "source": [
    "# peak finding procedure from notebook 04\n",
    "\n",
    "data = numpy.log(facepoly[\"circular_compactness_index\"])\n",
    "\n",
    "# adjust linspace to be sparser than observations (linspace contains 10x less datapoints than original data)\n",
    "n = int(len(data)/10)\n",
    "mylinspace = numpy.linspace(data.min(), data.max(), n)\n",
    "\n",
    "# fit Gaussian KDE\n",
    "kde = gaussian_kde(data, bw_method=\"silverman\")\n",
    "pdf = kde.pdf(mylinspace)\n",
    "\n",
    "# find peaks\n",
    "peaks, d = find_peaks(\n",
    "    x = -pdf +1,\n",
    "    height = (0,.995),\n",
    "    threshold = None,\n",
    "    distance = None,\n",
    "    prominence = 0.0005,\n",
    "    width = 1,\n",
    "    plateau_size = None)\n",
    "    \n",
    "banana = float(numpy.exp(mylinspace[peaks]))\n",
    "print(f\"banana value found for {city}: {banana}\")\n",
    "\n",
    "# add banana/non-banana classification to face polygon gdf\n",
    "facepoly[\"banana\"] = None\n",
    "facepoly.loc[facepoly[\"circular_compactness_index\"]<banana, \"banana\"] = \"banana\"\n",
    "facepoly.loc[facepoly[\"circular_compactness_index\"]>=banana, \"banana\"] = \"urbanblock\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semi-automated validation with building data from OSM\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in / download OSM building data for city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter warnings about GeoParquet implementation.\n",
    "warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
    "\n",
    "if os.path.exists(f\"../data/buildings/buildings_Vienna.gpkg\"):\n",
    "    \n",
    "    buildings = geopandas.read_file(f\"../data/buildings/buildings_Vienna.gpkg\")\n",
    "    \n",
    "    # project to same (projected) CRS as the face polygons\n",
    "    buildings = buildings.to_crs(facepoly.crs)\n",
    "\n",
    "# check if file exists - if it doesn't, download from OSM:\n",
    "if not os.path.exists(f\"../data/buildings/buildings_Vienna.gpkg\"):\n",
    "\n",
    "    # Loop over all samples\n",
    "    for ix, row in tqdm(sample_mini.iterrows(), total=len(sample_mini)):\n",
    "        \n",
    "        print(row.eFUA_name)\n",
    "\n",
    "        # Download OSM buildings\n",
    "        buildings = ox.geometries_from_polygon(\n",
    "            row.geometry, \n",
    "            tags = {\"building\": True})\n",
    "        buildings_small = buildings[[\"building\", \"geometry\"]] # saving only most relevant columns\n",
    "        buildings_small.to_file(f\"../data/buildings/buildings_{row.eFUA_name}.gpkg\", index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each polygon, use rtree and then intersection area computation to check whether building polygons are contained inside. \n",
    "\n",
    "**Note:** We introduce a \"building tolerance\" of 100m2. Reason: bananas can contain smaller objects tagged as buildings in OSM, such as bus stop roofs. So we will say that a face polygon contains a building only if it contains over 100m2 of built area.\n",
    "**This excludes all buildings saved as Points in the building data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make rtree of *buildings*\n",
    "mytree = strtree.STRtree(geoms = buildings.geometry)\n",
    "\n",
    "# query indeces of buildings that are CONTAINED by the banana (attention false positives!)\n",
    "facepoly[\"contains_indeces\"] = facepoly.apply(\n",
    "        lambda x: \n",
    "            mytree.query(x.geometry, predicate = \"contains\"), \n",
    "        axis = 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add areas of buildings-in-facepolygon\n",
    "facepoly[\"contains_area\"] = None\n",
    "\n",
    "for i in facepoly.index:\n",
    "    facepoly.loc[i, \"contains_area\"] = sum(facepoly.loc[i, \"geometry\"].intersection(\n",
    "        buildings.loc[facepoly.loc[i, \"contains_indeces\"], \"geometry\"]\n",
    "        ).area)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a simple yes-no for \"contains buildings\" (of any area > 0m2)\n",
    "facepoly[\"contains_buildings\"] = facepoly.apply(\n",
    "    lambda x: x.contains_area > 0, \n",
    "    axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add an area cutoff of 100m2 to the contains yes/no\n",
    "\n",
    "facepoly[\"contains_buildings_over100m2\"] = facepoly.apply(\n",
    "    lambda x: x.contains_area > 100, \n",
    "    axis = 1\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion matrix for bananas:**\n",
    "* *TP - true positive*: we correctly identified a banana. \n",
    "* *TN - true negative*: we correctly identified an urban block (non-banana)\n",
    "* *FP - false positive*: we thought it's a banana, but it's actually an urban block.\n",
    "* *FN - false negative*: we thought it's not a banana, but it actually is.\n",
    "\n",
    "**Partial automation of setting up the confusion matrix with help of building validation from OSM**:\n",
    "preliminary classifications with help of face polygon gdf:\n",
    "* *TP*: `banana=banana` and `contains_buildings_over100m2=False` \n",
    "* *TN*: `banana=urbanblock` and `contains_buildings_over100m2=True`\n",
    "* *FP*: `banana=banana` and `contains_buildings_over100m2=True`\n",
    "* *FN*: `banana=urbanblock` and `contains_buildings_over100m2=False` \n",
    "after this, check and correct classifications in QGIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add confusion matrix\n",
    "facepoly[\"confusion\"] = \"unknown\"\n",
    "\n",
    "# true positive\n",
    "facepoly.loc[\n",
    "        (facepoly[\"banana\"] == \"banana\") & \n",
    "        (facepoly[\"contains_buildings_over100m2\"]==False), \n",
    "    \"confusion\"] = \"tp\"\n",
    "\n",
    "# true negative\n",
    "facepoly.loc[\n",
    "        (facepoly[\"banana\"] == \"urbanblock\") & \n",
    "        (facepoly[\"contains_buildings_over100m2\"]==True), \n",
    "    \"confusion\"] = \"tn\"\n",
    "\n",
    "# false positive\n",
    "facepoly.loc[\n",
    "        (facepoly[\"banana\"] == \"banana\") & \n",
    "        (facepoly[\"contains_buildings_over100m2\"]==True), \n",
    "    \"confusion\"] = \"fp\"\n",
    "    \n",
    "# false negative\n",
    "facepoly.loc[\n",
    "        (facepoly[\"banana\"] == \"urbanblock\") & \n",
    "        (facepoly[\"contains_buildings_over100m2\"]==0), \n",
    "    \"confusion\"] = \"fn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'tn': 13117, 'tp': 3438, 'fn': 725, 'fp': 79})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(facepoly.confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export as pickle for further data analysis in notebooks\n",
    "facepoly.to_pickle(\"../results/facepoly_classified.pickle\")\n",
    "\n",
    "# export as gpkg for manual checks in QGIS\n",
    "facepoly[[\"geometry\", \"confusion\"]].to_file(\n",
    "    \"../../../bananas-qgis/confusionmatrix_Vienna.gpkg\", index = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OSMNX",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35f35e1f0bb92e7ac05765c87ada263d1a2173e12d4a4460e46e5d1567b982a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
