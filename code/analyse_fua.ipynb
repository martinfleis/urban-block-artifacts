{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse a sample of 25 functional urban areas from each continent\n",
    "\n",
    "This notebook downloads the boundaries of FUAs from GHSL, randomly samples 25 of them from each continent to account for various sizes and geographical variation, downloads street networks from OpenStreetMap and measures areas and circular compactness of polygons enclosed by street network geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import unicodedata\n",
    "\n",
    "import geopandas\n",
    "import numpy\n",
    "import pandas\n",
    "import pooch\n",
    "import pygeos\n",
    "import osmnx as ox\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data\n",
    "\n",
    "Download FUA polygons. We are using _GHS functional urban areas, derived from GHS-UCDB R2019A (2015)_ from [GHSL - Global Human Settlement Layer](https://ghsl.jrc.ec.europa.eu/ghs_fua.php)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fua_path = \"https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/GHSL/GHS_FUA_UCDB2015_GLOBE_R2019A/V1-0/GHS_FUA_UCDB2015_GLOBE_R2019A_54009_1K_V1_0.zip\"\n",
    "\n",
    "fua_cache = pooch.retrieve(fua_path, known_hash=\"d54de59b82b8c4d64a710f90ccd554975a3be92233f14115ac154094c3549979\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read polygons and continent geometry (built-in dataset in geopandas coming from Natural Earth)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fua = geopandas.read_file(f\"{fua_cache}!GHS_FUA_UCDB2015_GLOBE_R2019A_54009_1K_V1_0.gpkg\")\n",
    "continents = geopandas.read_file(geopandas.datasets.get_path(\"naturalearth_lowres\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attach information on a continent to FUAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fua = fua.merge(continents[[\"continent\", \"iso_a3\"]], left_on=\"Cntry_ISO\", right_on=\"iso_a3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample 25 FUAs from each continent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = []\n",
    "for continent in fua.continent.unique():\n",
    "    sample.append(fua[fua.continent == continent].sample(25, random_state=42))\n",
    "sample = pandas.concat(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reproject geometry to WGS84 required by OSM and check geometry validity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample.to_crs(4326)\n",
    "if not sample.is_valid.all():\n",
    "    sample.geometry = sample.buffer(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over the sampled FUAs and download their street network from OSM. This step may take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 150/150 [4:50:11<00:00, 116.08s/it]\n"
     ]
    }
   ],
   "source": [
    "# Filter warnings about GeoParquet implementation.\n",
    "warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
    "\n",
    "# Define which combination of OSM tags should be used. This covers what would be usually used in a morphological analysis.\n",
    "type_filter = '[\"highway\"~\"living_street|motorway|motorway_link|pedestrian|primary|primary_link|residential|secondary|secondary_link|service|tertiary|tertiary_link|trunk|trunk_link\"]'\n",
    "\n",
    "# Loop over all samples\n",
    "for ix, row in tqdm(sample.iterrows(), total=len(sample)):\n",
    "    # Download OSM graph\n",
    "    streets_graph = ox.graph_from_polygon(row.geometry, network_type='all_private', custom_filter=type_filter, retain_all=True)\n",
    "    # Project graph to the local UTM zone (in meters with a reletively small error)\n",
    "    streets_graph = ox.projection.project_graph(streets_graph)\n",
    "    # Create an undirected graph to avoid duplicated geometry and convert it to a GeoDataFrame\n",
    "    gdf = ox.graph_to_gdfs(ox.get_undirected(streets_graph), nodes=False, edges=True, node_geometry=False, fill_edge_geometry=True)\n",
    "    # Ensure tags are a string and not different dtype (as list) so we can save it\n",
    "    gdf.highway = gdf.highway.astype(str)\n",
    "    \n",
    "    # Create a folder for the sample case\n",
    "    os.makedirs(f\"../data/{int(row.eFUA_ID)}\", exist_ok=True)\n",
    "    \n",
    "    # Save the street network as a GeoParquet, using only necessary columns. We are not interested in other.\n",
    "    path =  f\"../data/{int(row.eFUA_ID)}/roads_osm.parquet\"\n",
    "    gdf[['highway', 'geometry']].to_parquet(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save sample boundaries containing names and continents for a future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_parquet(\"../data/sample.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure shape characteristics\n",
    "\n",
    "Polygonize the network to get polygons fully enclosed by street network geometry (sometimes called blocks, negative space...) and measure their shape characteristics. For the 2-D scattter plot showing the _banana_ shape, we need polygon area and Reock (circular) compactness [Measure A1 in Altman (1998), cited for Frolov (1974), but earlier from Reock (1963)]. For the 1-D histogram, we derive a custom shape index from polygon's area and an area of its mimimum bounding circle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 150/150 [00:58<00:00,  2.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# Filter warnings about GeoParquet implementation.\n",
    "warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
    "\n",
    "\n",
    "# Loop over unique FUA IDs\n",
    "for fua_id in tqdm(sample.eFUA_ID, total=len(sample)):\n",
    "    # Read stret network\n",
    "    roads = geopandas.read_parquet(f\"../data/{int(fua_id)}/roads_osm.parquet\")\n",
    "\n",
    "    # Polygonize street network\n",
    "    polygons = pygeos.polygonize(roads.geometry.array.data)\n",
    "    \n",
    "    # Store geometries as a GeoDataFrame\n",
    "    polygons = geopandas.GeoDataFrame(\n",
    "        geometry=geopandas.GeoSeries(\n",
    "            [polygons], crs=roads.crs\n",
    "        ).explode(ignore_index=True)\n",
    "    )\n",
    "\n",
    "    # Extract underlying PyGEOS geometries pygeos understands (minimum_bounding_circle is not yet exposed in geopandas)\n",
    "    ga = polygons.geometry.array.data\n",
    "\n",
    "    # measure area\n",
    "    polygons[\"area\"] = polygons.area\n",
    "    # generate minimum bounding circle\n",
    "    polygons[\"bounding_circle\"] = geopandas.GeoSeries(pygeos.minimum_bounding_circle(ga), crs=polygons.crs)\n",
    "    # measure MBC's area\n",
    "    polygons[\"circle_area\"] = polygons[\"bounding_circle\"].area\n",
    "    # measure Reock (circular) compactness\n",
    "    polygons[\"reock\"] = polygons[\"area\"] / polygons[\"circle_area\"]\n",
    "    # measure direct shape index that captures banana-like relationship between area and Reock compactness in a one dimension\n",
    "    polygons[\"shape_index\"] = polygons[\"area\"] / numpy.sqrt(polygons[\"circle_area\"])\n",
    "    \n",
    "    # save polygons to a GeoParquet\n",
    "    polygons.to_parquet(f\"../data/{int(fua_id)}/polygons.parquet\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d8e5257d6aa3ccb45d262d25a4bd441591d0aff640b224e205b1e70b23b1db26"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
